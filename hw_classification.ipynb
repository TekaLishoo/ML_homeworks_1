{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{2C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, eta=0.001, max_iter=1000, C=1.0, tol=1e-5, random_state=42, zero_init=False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = np.random.RandomState(seed=random_state)\n",
    "        self.zero_init = zero_init\n",
    "         \n",
    "    def get_sigmoid(self, X, weights):\n",
    "        \"\"\"Compute the sigmoid value.\"\"\"\n",
    "        dot_w_x = X @ weights\n",
    "        return (1 / (1 + np.exp(-dot_w_x)))\n",
    "    \n",
    "    def get_loss(self, x, weights, y):\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        l_y_preds = []\n",
    "        for ii in range(y.shape[0]):\n",
    "            l_y_preds.append(X_ext[ii, :] @ weights * y[ii])\n",
    "        return ((1 / y.shape[0]) * (np.sum(np.log(1 + np.exp(-np.array(l_y_preds))))) + ((1 / (2*self.C)) * np.sum(weights ** 2)))\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X]) # a constant feature is included to handle intercept\n",
    "        num_features = X_ext.shape[1]\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features) \n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low=-weight_threshold,\n",
    "                                                      high=weight_threshold, size=num_features) # random weight initialization \n",
    "        self.list_weights_ = []\n",
    "        self.list_weights_.append(list(self.weights_))\n",
    "        for i in range(self.max_iter):\n",
    "            l_slog = []\n",
    "            for ii in range(y.shape[0]):\n",
    "                list_slog = y[ii] * X_ext[ii, :] * (1 - 1 / (1 + np.exp(-X_ext[ii, :] @ self.weights_ * y[ii])))\n",
    "                l_slog.append(list_slog)\n",
    "            delta = -np.sum(np.array(l_slog), axis = 0)/ X_ext.shape[0] + self.weights_/self.C\n",
    "            self.weights_ -= self.eta * delta\n",
    "            self.list_weights_.append(list(self.weights_))\n",
    "            \n",
    "            if np.sqrt(np.sum(delta ** 2)) < self.tol:\n",
    "                print('break')\n",
    "                break\n",
    "        \n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'weights_'):\n",
    "            cl = self.predict_proba(X)\n",
    "            return np.where(cl < 0.5, -1, 1)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "#y_train = \"<your code>\"\n",
    "#y_test = \"<your code>\"\n",
    "y_train = (y_train % 2) * 2 - 1\n",
    "y_test = (y_test % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(y_pred=clf.predict(X_train), y_true=y_train), \\\n",
    "           metrics.accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter=1, zero_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.13152401e-03  0.00000000e+00 -4.17536534e-02 -5.47668754e-01\n",
      " -2.21294363e-01 -4.87473904e-01 -1.35768963e+00 -5.97773138e-01\n",
      " -5.63674322e-02  6.95894224e-04 -1.69102296e-01 -2.51913709e-01\n",
      "  4.37021573e-01 -3.61864997e-01 -1.00487126e+00 -4.22755741e-01\n",
      " -2.57480863e-02 -3.47947112e-04  1.14822547e-02  7.24425887e-01\n",
      "  2.62004175e-01 -8.75434934e-01 -4.15448852e-01  8.42032011e-02\n",
      "  5.21920668e-03  0.00000000e+00  2.21642310e-01  5.71329158e-01\n",
      " -9.85734168e-01 -1.35073069e+00 -5.02087683e-01  1.70494085e-01\n",
      "  1.04384134e-03  0.00000000e+00  6.78148921e-01  1.05149617e+00\n",
      "  4.45372303e-02 -3.71607516e-01 -4.21016006e-01  8.17675713e-02\n",
      "  0.00000000e+00  5.21920668e-03  5.34098817e-01  2.03931802e+00\n",
      "  8.43075852e-01 -1.04036186e-01  1.23869172e-01  1.78844816e-01\n",
      "  1.32219903e-02  4.52331246e-03  9.42936674e-02  1.11273486e+00\n",
      "  5.09046625e-01  2.18510786e-01  5.60542797e-01  3.95615866e-01\n",
      "  1.77453027e-02  3.47947112e-04 -2.67919276e-02 -6.39178845e-01\n",
      " -1.80932498e-01  7.36604036e-01  5.39318024e-01  3.70563674e-01\n",
      "  2.81837161e-02]\n"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([ 3.1000e-06,  0.0000e+00,  4.1800e-05,  5.4770e-04,  2.2130e-04,\n",
    "        4.8750e-04,  1.3577e-03,  5.9780e-04,  5.6400e-05, -7.0000e-07,\n",
    "        1.6910e-04,  2.5190e-04, -4.3700e-04,  3.6190e-04,  1.0049e-03,\n",
    "        4.2280e-04,  2.5700e-05,  3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "       -2.6200e-04,  8.7540e-04,  4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "        0.0000e+00, -2.2160e-04, -5.7130e-04,  9.8570e-04,  1.3507e-03,\n",
    "        5.0210e-04, -1.7050e-04, -1.0000e-06,  0.0000e+00, -6.7810e-04,\n",
    "       -1.0515e-03, -4.4500e-05,  3.7160e-04,  4.2100e-04, -8.1800e-05,\n",
    "        0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "        1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "       -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "       -3.9560e-04, -1.7700e-05, -3.0000e-07,  2.6800e-05,  6.3920e-04,\n",
    "        1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9109255393180237, 0.9388888888888889)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert min(train_acc, test_acc) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_weights_ = np.array(model.list_weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.698369699373699, 0.6942069212587795, 0.6933170224410479, 0.6936032673847956, 0.6947039716171022, 0.6964837687656825, 0.6988466003361806, 0.7017104115410515, 0.7050026831288673, 0.7086591085273979, 0.7126228402312029, 0.7168438415747534, 0.7212782558519816, 0.7258877871536112, 0.7306391042568247, 0.7355032790353584, 0.7404552671553264, 0.7454734349956527, 0.7505391337208405, 0.7556363193287696, 0.7607512161519712, 0.7658720205224991, 0.7709886409529957, 0.7760924711084964, 0.7811761919462743, 0.7862335996131998, 0.791259455961689, 0.7962493588423073, 0.8011996296312568, 0.8061072157403071, 0.8109696061271859, 0.8157847580718075, 0.8205510337064991, 0.8252671449866813, 0.8299321059634577, 0.8345451913729461, 0.8391059006909615, 0.8436139269178551, 0.8480691294589686, 0.8524715105531311, 0.8568211947766817, 0.8611184112151621, 0.8653634779505248, 0.8695567885596456, 0.8736988003611803, 0.877790024183327, 0.8818310154556226, 0.8858223664542351, 0.8897646995528936, 0.8936586613511721, 0.8975049175686991, 0.9013041486084573, 0.9050570457049114, 0.9087643075836017, 0.9124266375682669, 0.9160447410797147, 0.919619323477761, 0.9231510882036864, 0.926640735186012, 0.9300889594770358, 0.933496450091619, 0.936863889023229, 0.9401919504153204, 0.9434812998688219, 0.9467325938688318, 0.9499464793156793, 0.9531235931473019, 0.9562645620414586, 0.9593700021876759, 0.9624405191200327, 0.9654767076029531, 0.9684791515631032, 0.9714484240613152, 0.974385087299178, 0.9772896926555706, 0.980162780748978, 0.9830048815219155, 0.9858165143442333, 0.9885981881324473, 0.9913504014825876, 0.994073642814358, 0.9967683905246569, 0.9994351131487569, 1.0020742695276303, 1.004686308980116, 1.0072716714787564, 1.0098307878283057, 1.012364079846014, 1.0148719605429235, 1.0173548343054981, 1.0198130970770087, 1.022247136538164, 1.0246573322865553, 1.0270440560145362, 1.0294076716852225, 1.0317485357063374, 1.0340669971016714, 1.0363633976799675, 1.0386380722010733, 1.0408913485392264, 1.0431235478433756, 1.0453349846944515, 1.0475259672595292, 1.0496967974428364, 1.051847771033583, 1.0539791778505914, 1.0560913018837321, 1.058184421432165, 1.060258809239404, 1.062314732625234, 1.0643524536145006, 1.0663722290628161, 1.0683743107792212, 1.0703589456458409, 1.0723263757345933, 1.074276838420988, 1.0762105664950814, 1.0781277882696316, 1.0800287276855183, 1.0819136044144755, 1.0837826339592045, 1.085636027750917, 1.0874739932443735, 1.0892967340104696, 1.0911044498264326, 1.0928973367636845, 1.0946755872734306, 1.0964393902700265, 1.0981889312121837, 1.0999243921820692, 1.1016459519623505, 1.10335378611124, 1.105048067035596, 1.1067289640621254, 1.1083966435067445, 1.110051268742142, 1.111693000263599, 1.1133219957531058, 1.114938410141828, 1.1165423956709666, 1.118134101951049, 1.1197136760197055, 1.1212812623979629, 1.1228370031451005, 1.1243810379121102, 1.1259135039937935, 1.1274345363795406, 1.12894426780282, 1.1304428287894221, 1.131930347704485, 1.1334069507983426, 1.1348727622512196, 1.1363279042168135, 1.1377724968647902, 1.1392066584222234, 1.1406305052140064, 1.14204415170227, 1.1434477105248246, 1.1448412925326636, 1.1462250068265434, 1.147598960792679, 1.148963260137563, 1.150318008921946, 1.151663309593994, 1.1529992630216477, 1.1543259685242042, 1.1556435239031435, 1.1569520254722212, 1.1582515680868406, 1.1595422451727375, 1.1608241487539772, 1.1620973694803036, 1.1633619966538382, 1.1646181182551583, 1.165865820968769, 1.1671051902079803, 1.1683363101392146, 1.1695592637057448, 1.1707741326508967, 1.1719809975407123, 1.1731799377861016, 1.1743710316644864, 1.1755543563409563, 1.1767299878889466, 1.177898001310449, 1.1790584705557727, 1.1802114685428586, 1.1813570671761708, 1.1824953373651608, 1.1836263490423289, 1.1847501711808865, 1.1858668718120282, 1.1869765180418304, 1.1880791760677765, 1.1891749111949275, 1.1902637878517373, 1.1913458696055337, 1.192421219177659, 1.1934898984582936, 1.1945519685209558, 1.1956074896366986, 1.1966565212880038, 1.1976991221823818, 1.1987353502656848, 1.1997652627351434, 1.2007889160521272, 1.2018063659546419, 1.202817667469565, 1.2038228749246311, 1.204822041960167, 1.2058152215405877, 1.2068024659656564, 1.2077838268815146, 1.2087593552914873, 1.209729101566672, 1.2106931154563099, 1.2116514460979504, 1.2126041420274125, 1.2135512511885458, 1.2144928209427974, 1.215428898078589, 1.2163595288205082, 1.2172847588383187, 1.2182046332557945, 1.219119196659379, 1.2200284931066767, 1.2209325661347792, 1.2218314587684305, 1.2227252135280324, 1.223613872437499, 1.2244974770319574, 1.2253760683653039, 1.226249687017613, 1.2271183731024091, 1.2279821662737964, 1.228841105733461, 1.2296952302375312, 1.23054457810332, 1.2313891872159337, 1.2322290950347607, 1.233064338599841, 1.2338949545381137, 1.2347209790695544, 1.2355424480131962, 1.2363593967930417, 1.2371718604438664, 1.2379798736169183, 1.2387834705855112, 1.2395826852505196, 1.240377551145773, 1.241168101443354, 1.2419543689588013, 1.2427363861562188, 1.243514185153297, 1.244287797726241, 1.2450572553146142, 1.2458225890260979, 1.2465838296411622, 1.2473410076176612, 1.2480941530953436, 1.2488432959002875, 1.2495884655492562, 1.2503296912539805, 1.2510670019253665, 1.2518004261776303, 1.252529992332364, 1.2532557284225303, 1.253977662196389, 1.2546958211213588, 1.2554102323878138, 1.256120922912813, 1.2568279193437688, 1.257531248062057, 1.2582309351865621, 1.2589270065771647, 1.2596194878381737, 1.2603084043216972, 1.2609937811309633, 1.261675643123581, 1.262354014914751, 1.2630289208804224, 1.263700385160399, 1.2643684316613955, 1.2650330840600414, 1.2656943658058408, 1.2663523001240813, 1.2670069100186958, 1.267658218275082, 1.2683062474628746, 1.2689510199386718, 1.2695925578487222, 1.270230883131567, 1.2708660175206417, 1.2714979825468344, 1.2721267995410082, 1.27275248963648, 1.273375073771464, 1.2739945726914754, 1.2746110069516972, 1.275224396919312, 1.275834762775794, 1.276442124519171, 1.2770465019662485, 1.2776479147548, 1.2782463823457257, 1.278841924025177, 1.279434558906648, 1.2800243059330403, 1.2806111838786896, 1.2811952113513674, 1.2817764067942512, 1.282354788487865, 1.2829303745519902, 1.2835031829475505, 1.284073231478467, 1.284640537793487, 1.2852051193879854, 1.2857669936057392, 1.2863261776406782, 1.2868826885386084, 1.2874365431989097, 1.2879877583762114, 1.2885363506820429, 1.289082336586458, 1.2896257324196392, 1.2901665543734786, 1.2907048185031333, 1.2912405407285623, 1.291773736836041, 1.2923044224796507, 1.292832613182752, 1.2933583243394353, 1.2938815712159488, 1.2944023689521107, 1.2949207325626995, 1.295436676938824, 1.295950216849276, 1.2964613669418648, 1.2969701417447301, 1.2974765556676398, 1.2979806230032709, 1.298482357928468, 1.2989817745054901, 1.299478886683238, 1.2999737082984635, 1.3004662530769648, 1.300956534634767, 1.3014445664792804, 1.301930362010451, 1.3024139345218906, 1.302895297201993, 1.303374463135037, 1.3038514453022725, 1.3043262565829918, 1.3047989097555923, 1.3052694174986146, 1.3057377923917803, 1.3062040469170042, 1.306668193459401, 1.3071302443082753, 1.3075902116580997, 1.308048107609481, 1.3085039441701123, 1.308957733255715, 1.3094094866909654, 1.309859216210413, 1.310306933459386, 1.3107526499948832, 1.311196377286457, 1.3116381267170842, 1.3120779095840265, 1.312515737099679, 1.3129516203924085, 1.3133855705073816, 1.313817598407383, 1.3142477149736222, 1.31467593100653, 1.3151022572265478, 1.3155267042749035, 1.3159492827143813, 1.3163700030300785, 1.3167888756301553, 1.3172059108465772, 1.3176211189358427, 1.3180345100797068, 1.3184460943858962, 1.3188558818888103, 1.3192638825502219, 1.3196701062599603, 1.3200745628365955, 1.3204772620281064, 1.3208782135125448, 1.3212774268986924, 1.3216749117267061, 1.3220706774687605, 1.3224647335296775, 1.3228570892475544, 1.323247753894378, 1.3236367366766384, 1.324024046735929, 1.3244096931495446, 1.3247936849310697, 1.3251760310309615, 1.3255567403371245, 1.3259358216754797, 1.3263132838105274, 1.3266891354459018, 1.327063385224923, 1.3274360417311355, 1.3278071134888507, 1.3281766089636733, 1.3285445365630284, 1.3289109046366794, 1.3292757214772415, 1.329638995320688, 1.3300007343468527, 1.3303609466799247, 1.3307196403889394, 1.3310768234882635, 1.3314325039380732, 1.3317866896448292, 1.3321393884617452, 1.3324906081892505, 1.3328403565754512, 1.3331886413165799, 1.3335354700574473, 1.3338808503918833, 1.334224789863178, 1.3345672959645125, 1.3349083761393914, 1.3352480377820648, 1.3355862882379494, 1.3359231348040437, 1.336258584729338, 1.336592645215222, 1.3369253234158864, 1.3372566264387211, 1.3375865613447069, 1.337915135148808, 1.3382423548203544, 1.338568227283424, 1.3388927594172209, 1.3392159580564458, 1.3395378299916685, 1.3398583819696899, 1.340177620693906, 1.3404955528246647, 1.340812184979619, 1.341127523734079, 1.3414415756213567, 1.3417543471331106, 1.3420658447196843, 1.3423760747904425, 1.3426850437141045, 1.342992757819072, 1.3432992233937557, 1.3436044466868984, 1.3439084339078924, 1.3442111912270966, 1.34451272477615, 1.344813040648279, 1.3451121448986056, 1.345410043544451, 1.3457067425656337, 1.34600224790477, 1.3462965654675647, 1.346589701123106, 1.3468816607041512, 1.3471724500074138, 1.3474620747938455, 1.347750540788918, 1.3480378536828965, 1.3483240191311183, 1.3486090427542614, 1.3488929301386159, 1.3491756868363491, 1.3494573183657699, 1.3497378302115899, 1.3500172278251823, 1.3502955166248385, 1.3505727019960208, 1.350848789291615, 1.3511237838321792, 1.351397690906189, 1.3516705157702835, 1.351942263649505, 1.352212939737541, 1.3524825491969592, 1.352751097159444, 1.3530185887260282, 1.353285028967324, 1.3535504229237518, 1.3538147756057655, 1.3540780919940774, 1.3543403770398794, 1.3546016356650639, 1.3548618727624402, 1.3551210931959523, 1.3553793018008904, 1.3556365033841051, 1.3558927027242154, 1.3561479045718168, 1.3564021136496887, 1.3566553346529973, 1.3569075722494974, 1.3571588310797347, 1.357409115757242, 1.3576584308687376, 1.35790678097432, 1.3581541706076594, 1.3584006042761916, 1.3586460864613068, 1.3588906216185357, 1.3591342141777385, 1.359376868543288, 1.3596185890942531, 1.3598593801845793, 1.3600992461432693, 1.3603381912745598, 1.3605762198581002, 1.360813336149125, 1.361049544378629, 1.3612848487535378, 1.3615192534568787, 1.36175276264795, 1.3619853804624877, 1.362217111012831, 1.3624479583880875, 1.3626779266542954, 1.362907019854586, 1.3631352420093428, 1.363362597116361, 1.363589089151004, 1.36381472206636, 1.364039499793397, 1.3642634262411149, 1.3644865052966995, 1.3647087408256702, 1.3649301366720321, 1.3651506966584233, 1.3653704245862601, 1.3655893242358856, 1.3658073993667117, 1.3660246537173633, 1.366241091005819, 1.3664567149295537, 1.3666715291656766, 1.3668855373710695, 1.3670987431825263, 1.3673111502168849, 1.3675227620711663, 1.3677335823227048, 1.3679436145292836, 1.3681528622292647, 1.3683613289417196, 1.3685690181665577, 1.3687759333846579, 1.3689820780579909, 1.36918745562975, 1.369392069524473, 1.3695959231481676, 1.3697990198884356, 1.370001363114592, 1.3702029561777889, 1.370403802411134, 1.370603905129811, 1.3708032676311956, 1.3710018931949752, 1.3711997850832638, 1.3713969465407163, 1.3715933807946457, 1.371789091055133, 1.3719840805151426, 1.3721783523506328, 1.3723719097206664, 1.3725647557675202, 1.3727568936167946, 1.3729483263775224, 1.3731390571422737, 1.3733290889872645, 1.3735184249724612, 1.3737070681416856, 1.373895021522719, 1.374082288127404, 1.374268870951748, 1.3744547729760246, 1.3746399971648735, 1.3748245464674005, 1.3750084238172773, 1.3751916321328392, 1.375374174317182, 1.37555605325826, 1.3757372718289813, 1.3759178328873032, 1.3760977392763263, 1.3762769938243888, 1.3764555993451606, 1.3766335586377325, 1.3768108744867114, 1.3769875496623083, 1.3771635869204317, 1.3773389890027736, 1.3775137586369015, 1.3776878985363443, 1.3778614114006802, 1.3780342999156256, 1.3782065667531185, 1.3783782145714059, 1.378549246015127, 1.3787196637154002, 1.3788894702899035, 1.3790586683429595, 1.3792272604656173, 1.379395249235734, 1.379562637218056, 1.3797294269643, 1.3798956210132312, 1.3800612218907453, 1.3802262321099448, 1.3803906541712179, 1.3805544905623175, 1.3807177437584355, 1.3808804162222819, 1.3810425104041582, 1.3812040287420349, 1.3813649736616247, 1.3815253475764582, 1.381685152887955, 1.3818443919854997, 1.3820030672465125, 1.382161181036522, 1.3823187357092375, 1.3824757336066176, 1.3826321770589431, 1.3827880683848863, 1.3829434098915792, 1.3830982038746846, 1.3832524526184629, 1.3834061583958404, 1.3835593234684773, 1.383711950086834, 1.3838640404902387, 1.3840155969069523, 1.3841666215542334, 1.3843171166384056, 1.3844670843549205, 1.3846165268884223, 1.384765446412811, 1.384913845091306, 1.38506172507651, 1.385209088510469, 1.3853559375247366, 1.385502274240434, 1.3856481007683112, 1.3857934192088082, 1.385938231652115, 1.3860825401782306, 1.386226346857024, 1.3863696537482912, 1.3865124629018153, 1.3866547763574233, 1.3867965961450448, 1.386937924284769, 1.3870787627869012, 1.3872191136520202, 1.3873589788710337, 1.3874983604252331, 1.3876372602863518, 1.387775680416617, 1.387913622768806, 1.3880510892862998, 1.3881880819031371, 1.388324602544068, 1.3884606531246069, 1.3885962355510844, 1.388731351720702, 1.3888660035215812, 1.3890001928328164, 1.3891339215245275, 1.3892671914579087, 1.389400004485281, 1.3895323624501408, 1.3896642671872106, 1.3897957205224891, 1.3899267242732996, 1.3900572802483393, 1.3901873902477275, 1.3903170560630551, 1.3904462794774308, 1.3905750622655302, 1.3907034061936414, 1.3908313130197147, 1.390958784493406, 1.391085822356126, 1.3912124283410843, 1.3913386041733358, 1.391464351569827, 1.3915896722394394, 1.3917145678830358, 1.3918390401935044, 1.3919630908558027, 1.3920867215470012, 1.3922099339363287, 1.3923327296852137, 1.3924551104473288, 1.3925770778686328, 1.3926986335874132, 1.3928197792343298, 1.3929405164324535, 1.3930608467973125, 1.3931807719369298, 1.3933002934518657, 1.3934194129352604, 1.3935381319728708, 1.3936564521431147, 1.393774375017109, 1.39389190215871, 1.3940090351245518, 1.3941257754640874, 1.3942421247196277, 1.3943580844263779, 1.3944736561124793, 1.394588841299045, 1.3947036415001997, 1.3948180582231169, 1.394932092968056, 1.3950457472283997, 1.395159022490693, 1.3952719202346773, 1.3953844419333283, 1.3954965890528934, 1.3956083630529255, 1.3957197653863216, 1.3958307974993562, 1.3959414608317182, 1.3960517568165456, 1.3961616868804605, 1.396271252443605, 1.3963804549196737, 1.3964892957159494, 1.396597776233338, 1.3967058978664004, 1.3968136620033882, 1.3969210700262764, 1.3970281233107957, 1.3971348232264675, 1.3972411711366364, 1.3973471683985004, 1.3974528163631472, 1.3975581163755844, 1.397663069774771, 1.3977676778936505, 1.397871942059182, 1.397975863592373, 1.3980794438083075, 1.3981826840161806, 1.398285585519328, 1.398388149615256, 1.398490377595673, 1.3985922707465195, 1.398693830347998, 1.3987950576746042, 1.3988959539951547, 1.3989965205728179, 1.399096758665144, 1.399196669524093, 1.3992962543960636, 1.399395514521924, 1.399494451137038, 1.3995930654712958, 1.399691358749141, 1.3997893321895991, 1.3998869870063062, 1.3999843244075352, 1.400081345596225, 1.4001780517700082, 1.4002744441212367, 1.4003705238370108, 1.4004662920992041, 1.400561750084493, 1.4006568989643808, 1.400751739905227, 1.40084627406827, 1.4009405026096564, 1.4010344266804666, 1.4011280474267391, 1.4012213659894979, 1.4013143835047772, 1.4014071011036464, 1.4014995199122378, 1.401591641051768, 1.4016834656385664, 1.4017749947840972, 1.4018662295949869, 1.4019571711730456, 1.4020478206152946, 1.4021381790139886, 1.4022282474566399, 1.402318027026043, 1.4024075188002996, 1.4024967238528385, 1.4025856432524442, 1.4026742780632755, 1.402762629344892, 1.4028506981522761, 1.4029384855358564, 1.4030259925415287, 1.4031132202106826, 1.4032001695802196, 1.4032868416825792, 1.4033732375457584, 1.4034593581933363, 1.403545204644495, 1.4036307779140411, 1.4037160790124277, 1.4038011089457783, 1.4038858687159044, 1.4039703593203297, 1.4040545817523118, 1.4041385370008603, 1.404222226050762, 1.404305649882598, 1.4043888094727675, 1.4044717057935063, 1.4045543398129094, 1.4046367124949497, 1.4047188247994988, 1.404800677682348, 1.404882272095228, 1.4049636089858286, 1.4050446892978186, 1.4051255139708656, 1.405206083940657, 1.4052864001389167, 1.405366463493427, 1.405446274928048, 1.4055258353627342, 1.4056051457135565, 1.4056842068927196, 1.4057630198085815, 1.4058415853656723, 1.4059199044647117, 1.40599797800263, 1.4060758068725845, 1.4061533919639775, 1.4062307341624771, 1.4063078343500326, 1.4063846934048947, 1.4064613122016316, 1.406537691611148, 1.406613832500703, 1.406689735733927, 1.406765402170839, 1.4068408326678656, 1.406916028077857, 1.4069909892501042, 1.4070657170303573, 1.4071402122608416, 1.4072144757802743, 1.4072885084238829, 1.40736231102342, 1.4074358844071813, 1.407509229400022, 1.4075823468233732, 1.4076552374952584, 1.4077279022303089, 1.4078003418397813, 1.4078725571315738, 1.4079445489102405, 1.4080163179770095, 1.4080878651297968, 1.4081591911632232, 1.4082302968686302, 1.4083011830340952, 1.4083718504444471, 1.4084422998812816, 1.4085125321229761, 1.4085825479447063, 1.4086523481184603, 1.408721933413054, 1.4087913045941463, 1.4088604624242538, 1.4089294076627656, 1.4089981410659582, 1.4090666633870106, 1.4091349753760183, 1.4092030777800075, 1.4092709713429517, 1.4093386568057826, 1.4094061349064075, 1.409473406379722, 1.4095404719576246, 1.4096073323690301, 1.409673988339885, 1.4097404405931802, 1.409806689848965, 1.409872736824361, 1.4099385822335764, 1.4100042267879185, 1.4100696711958085, 1.4101349161627934, 1.4101999623915613, 1.4102648105819526, 1.4103294614309756, 1.4103939156328178, 1.41045817387886, 1.4105222368576884, 1.4105861052551087, 1.410649779754159, 1.4107132610351216, 1.4107765497755358, 1.4108396466502127, 1.4109025523312444, 1.4109652674880204, 1.4110277927872357, 1.4110901288929085, 1.411152276466387, 1.411214236166367, 1.4112760086488996, 1.4113375945674063, 1.4113989945726895, 1.411460209312946, 1.4115212394337777, 1.4115820855782042, 1.411642748386674, 1.4117032284970774, 1.4117635265447575, 1.4118236431625208, 1.4118835789806516, 1.4119433346269206, 1.4120029107265986, 1.412062307902466, 1.4121215267748257, 1.4121805679615145, 1.4122394320779126, 1.4122981197369564, 1.4123566315491487, 1.4124149681225713, 1.4124731300628937, 1.4125311179733853, 1.4125889324549274, 1.4126465741060217, 1.4127040435228029, 1.4127613412990485, 1.4128184680261897, 1.4128754242933226, 1.412932210687218, 1.4129888277923317, 1.4130452761908159, 1.4131015564625293, 1.413157669185047, 1.4132136149336703, 1.4132693942814394, 1.4133250077991402, 1.4133804560553171, 1.4134357396162818, 1.4134908590461233, 1.4135458149067188, 1.4136006077577425, 1.4136552381566765, 1.4137097066588193, 1.4137640138172975, 1.4138181601830733, 1.4138721463049564, 1.4139259727296114, 1.4139796400015694, 1.4140331486632354, 1.4140864992549012, 1.41413969231475, 1.4141927283788707, 1.414245607981263, 1.4142983316538504, 1.414350899926486, 1.4144033133269645, 1.41445557238103, 1.4145076776123844, 1.4145596295426992, 1.4146114286916207, 1.4146630755767822, 1.4147145707138111, 1.4147659146163383, 1.4148171077960072, 1.4148681507624825, 1.414919044023458, 1.4149697880846672, 1.4150203834498896, 1.4150708306209612, 1.4151211300977822, 1.415171282378326, 1.4152212879586465, 1.4152711473328883, 1.4153208609932937, 1.4153704294302116, 1.415419853132106, 1.4154691325855635, 1.4155182682753022, 1.4155672606841803, 1.4156161102932023, 1.4156648175815303, 1.4157133830264887]\n"
     ]
    }
   ],
   "source": [
    "y_loss = []\n",
    "for i in range(model.max_iter):\n",
    "    y_loss.append(model.get_loss(X_train, list_weights_[i], y_train))\n",
    "    \n",
    "print(y_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_count = range(model.max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkV0lEQVR4nO3deXwV5dn/8c9lwiYosgRFlhIUUbQWa8QFrKD+KJX+1McVHqyo9MEd1NatVUF/rs+jj0urIioibQWxdUXFBUW0YAWKIG6AASGoELCAqSyBXL8/7hMIMQnZJnOW7/v1mlfOmZmcc00G5pp7mfs2d0dERDLXbnEHICIi8VIiEBHJcEoEIiIZTolARCTDKRGIiGS47LgDqKm2bdt6ly5d4g5DRCSlzJ07d42751S0LeUSQZcuXZgzZ07cYYiIpBQz+7KybaoaEhHJcEoEIiIZTolARCTDpVwbQUWKi4spKChg06ZNcYciQNOmTenYsSONGjWKOxQRqYa0SAQFBQXssccedOnSBTOLO5yM5u6sXbuWgoICcnNz4w5HRKohLaqGNm3aRJs2bZQEkoCZ0aZNG5XORFJIWiQCQEkgiehciKSWtKgaEhFJWVu3wnffQVERFBdD165h/bvvwooVYX1REbRpA0OHRhKCEkE9WLt2LSeccAIA33zzDVlZWeTkhAf4PvjgAxo3blzp786ZM4cJEybwwAMPVPkdxxxzDDNnzqxzrNOnT+fuu+9mypQpdf4skYxWVARr1sD69TuWf/8bBg0K2ydODBfz0gt5URFkZ8Mrr4Tt554LkyfD5s07PrNLF1i6NLy+5RZ4880d2/LyUi8RmNk44JfAanc/pIr9jgBmAYPc/a9RxROlNm3a8OGHHwIwevRoWrRowW9/+9vt27du3Up2dsV/6ry8PPLy8nb5HfWRBESkjH//G776Cr79Niz/+lf4ef750Lw5PPccTJq04yK/YUP4uWgR7L473HAD3H//zp9pBmedBbvtBjNnhgv9HnuEpUULaNt2x77HHw/t2+/YVn77mDGhtFC6vXnzyP4UUZYIxgN/BCZUtoOZZQF3Aa9HGEcszjvvPJo2bcq8efPo3bs3gwYNYuTIkWzatIlmzZrxxBNP0L17953u0EePHs3y5cvJz89n+fLlXHHFFYwYMQKAFi1aUFRUxPTp0xk9ejRt27Zl4cKFHH744fz5z3/GzHjllVe46qqraN68Ob179yY/P7/ad/4TJ07k9ttvx90ZOHAgd911F9u2bWPYsGHMmTMHM+OCCy7gyiuv5IEHHmDMmDFkZ2fTo0cPJk2aFOWfUqRyJSWwbh0UFobl22/hmGPCBXX2bHjiiZ0v8t9+G+7Iu3eHxx+HkSN/+JknnRSqZ77+Gj78EFq2DEuHDuHntm1hv0GD4Cc/2bF9zz3Dz1J/+ENYKnPeeVUf23771fCPUXuRJQJ3n2FmXXax2+XA34Aj6vXL+/b94bqzzoJLLoHvvw8nurzzzgvLmjVwxhk7b5s+vVZhFBQUMHPmTLKystiwYQPvvvsu2dnZvPnmm/zud7/jb3/72w9+57PPPuPtt9/mu+++o3v37lx88cU/6I8/b948Pv74Y/bdd1969+7N3//+d/Ly8rjwwguZMWMGubm5DB48uNpxfvXVV1x77bXMnTuXVq1a0b9/f55//nk6derEypUrWbhwIQDr1q0D4M4772Tp0qU0adJk+zqRelFSEi60jRqFi/fbb4cL/OrVOy72V1wBRx4JU6fCL3+548Jc6o034MQTQ/36M89A69bQqhXk5IQEUPr/qX9/+NOfwvbSpVWrUBcP4XpxySWVx3rUUWFJA7G1EZhZB+A/gH7UdyJIEmeeeSZZWVkArF+/nqFDh7J48WLMjOLi4gp/Z+DAgTRp0oQmTZrQrl07Vq1aRceOHXfap1evXtvX9ezZk2XLltGiRQu6du26ve/+4MGDGTt2bLXinD17Nn379t3erjFkyBBmzJjBjTfeSH5+PpdffjkDBw6kf//+ABx66KEMGTKEU089lVNPPbXGfxfJQJs3wzffhLvsvfeG3FxYtQp+//uwrnQpLISHHoLhwyE/H04/fcdntGwZLuZr1oT33brBNddAu3ZhfU5OuIgfcEDYftppYanMgQeGRWJtLL4PuNbdS3bV3dDMhgPDATp37rzrT67qDn733ave3rZtrUsA5TUvU6d344030q9fP5577jmWLVtG34pKLUCTJk22v87KymLr1q212qc+tGrVivnz5/Paa68xZswYJk+ezLhx43j55ZeZMWMGL730ErfddhsfffRRpW0gkubcw4V5xYodywEHhLvt776Do48OF/hvv93xOzfdBDffHOrTX3451JO3bw8//WlIEj17hv169IB588KFvm1bKN/pYr/94PbbG+xQ01mc/3vzgEmJJNAWOMnMtrr78+V3dPexwFiAvLw8b8gg68v69evp0KEDAOPHj6/3z+/evTv5+fksW7aMLl268PTTT1f7d3v16sWIESNYs2YNrVq1YuLEiVx++eWsWbOGxo0bc/rpp9O9e3fOOeccSkpKWLFiBf369aNPnz5MmjSJoqIi9tprr3o/JkkC69fD8uU7X+hzc2HYsJAE2rQJVThlDRsWEkGLFuGO+2c/23Gxb98eDkn0HWnXLiSJyjRrtiMpSKRiSwTuvn38ATMbD0ypKAmki2uuuYahQ4dy6623MnDgwHr//GbNmvHQQw8xYMAAmjdvzhFHVF7bNm3atJ2qm5555hnuvPNO+vXrt72x+JRTTmH+/Pmcf/75lJSUAHDHHXewbds2zjnnHNavX4+7M2LECCWBVLZ5M3z5ZeiymJ8flpYtQ48YCHfp+fk79s/KCu1tw4aFO/qrrw69WTp12rEkqhgxg7+mZEfAjGPu0dxgm9lEoC/hbn8VMApoBODuY8rtO56QCHb5ryYvL8/LT0zz6aefctBBB9VL3KmsqKiIFi1a4O5ceumldOvWjSuvvDKWWHROksh334Uuj4sWweLFsGnTjiqVfv12rgpt0iR0tpg6NbyfPDn8LL3I77NP6AsvKcfM5rp7hX3Vo+w1VO1uK+5+XlRxZJJHH32UJ598ki1btnDYYYdx4YUXxh2SNJTi4nBX//nn4Q5+xIhwR37JJfDwwzvv260b3HZb2D5yZOg3n5sbuky2bx/6wJc666yGPQ6JRWQlgqioRJAadE4isnlzuNh37x7u3p94Au64I1z8y3ajXL06VNG8+CJ88klowO3ePTSwNm0aX/wSm1hKBA3N3TXYWZJItZuLpLZ4MTz1FCxcGJbFi8MFf+7cUH/fpg0ceiiceWa40B9wQFhatw6/f/LJYRGpQlokgqZNm7J27VoNRZ0ESucjaKq7zur7/ntYsCB0lZw3D/75z1B18/Ofh4bcm2+G/feHgw8ODzseckgYkwZ0oZd6kRaJoGPHjhQUFFBYWBh3KMKOGcqkAuvWhYt927bw4x+HO/wDDwxP1EK4kz/ssNA7B0LXy6Ki8PyLSETSIhE0atRIs2FJciopgbFj4R//gPffh88+C+svvjg8QZubCzfeGPrLH3YYdO4cGnFLNW78wwepROpZWjQWiySFr78OF/v33w8PQ40eHdZ36RJGujzqqDBGTl5eWMqONCkSsYxoLBaJza23wpNPwpIl4X2jRlD2ocHZs8NFX+1XkqSUCESqwz1023znHZgxIzTofvRReLiquDg05F50EfTuHap5yjaWlz5pK5KklAhEduWZZ8KDV6Xj4uyzDxx3XGj4bds29OoRSWFKBCKlvv8+TC34+uthTPt774UTTggTkhx3XHh93HGhK6eqeSSNKBGIrFoV5oKdPj08udu4MfTps6ML5zHHhEUkTSkRSGYpKYEPPoCXXgrVOldeGZ7OXbcujMvz85/Dsceq375kFCUCyQzTpoWhGqZMCePwZGXBkCFhW3Z26PIpkqF22/UuIiloy5Zw8S81fnwYG//44+EvfwlTIj75ZGzhiSQTlQgkfRQXh4beyZPhhRfC7FoLF4aunffcA489FkbsFJGdKBFIepg9OzzEVVgIe+0Fp54axtLv1i1sb9cuzuhEkpoSgaSmFStCFU+nTqGu/6CD4MQTYdAgGDBA4/OI1IASgaSO4uJQ5TN2LLz5Znja99e/DomgRYvQGCwiNaZEIKnj7LPhuefCCJ2jRsGvfhWmVxSROoms15CZjTOz1Wa2sJLtp5jZAjP70MzmmFmfqGKRFLRtGzz/fKj3X7UqrBs5El5+OUzLOGqUkoBIPYmyRDAe+CMwoZLt04AX3d3N7FBgMnBghPFIKli/Hh5/HP7wB1i2LAzvsHgx7L13GN5BROpdZInA3WeYWZcqtheVedscSK2JEaT+rVsXxu5fvz483XvPPWEaxmzVYIpEKdb/YWb2H8AdQDtgYBX7DQeGA3Tu3LlhgpOGMXt2GOPn6qtDt89Ro8L0jIcfHndkIhkj0hnKEiWCKe5+yC72+xlwk7ufuKvP1AxlaeLdd8OELq+/Hsb6yc+HPfeMOyqRtFXVDGVJMcSEu88AupqZ5u5Ld599Fur6f/Yz+PBDuOsuWLpUSUAkRrFVDZnZ/sAXicbinwJNgLVxxSMR27AhXOxbtw4TvNx/f3gGQKN8isQuskRgZhOBvkBbMysARgGNANx9DHA6cK6ZFQMbgbM9ynoqiccHH8D114dJX2bODEM9fP65JnYRSSJR9hoavIvtdwF3RfX9ErNPPoEbbggPgOXkwO9/H+YCyMpSEhBJMuqXJ/XvlVfg//5faN48zOd75ZWwxx5xRyUilVAikPqxZUvo+XPggWHM/xtvhMsuC7OAiUhSS4peQ5LC3MO0jwcfHKZ53LwZmjaF0aOVBERShBKB1N7SpXDSSeHp36wsGDNGE7+IpCBVDUntLFwIvXqFBPC//xuqgRo1ijsqEakFJQKpmbVrw5PABx8M11wTngXo2DHuqESkDlQ1JNXz/fdhGOj99oOVK0MX0NGjlQRE0oBKBLJr778PQ4fCokWhCkjDQYikFZUIpHLu4UGw3r1h0yaYNi3ME6BnAkTSihKBVM4sjAt03nnw0Ufh+QARSTuqGpKducNjj8GRR8Khh8Kjj4aeQSKStlQikB02bID//E8YPhwefjisUxIQSXsqEUgwdy6cfXaYJ/j22+Haa+OOSEQaiBKBwN//Hur/27UL00b26RN3RCLSgFQ1JHDEEeEZgXnzlAREMpASQaYqLIRzzw1PCjduDP/93xokTiRDKRFkogULIC8PnnkmtA2ISEZTIsg0r78eqn+2bYP33oP+/eOOSERiFlkiMLNxZrbazBZWsn2ImS0ws4/MbKaZ/SSqWCThxRdh4EDIzQ3DRhx+eNwRiUgSiLJEMB4YUMX2pcBx7v5j4P8BYyOMRQCOOiqMGfTuuxosTkS2iywRuPsM4Nsqts90938l3r4P6MoUhW3b4MEHobg4dA997DENGiciO0mWNoJhwKuVbTSz4WY2x8zmFBYWNmBYKW7LlvCk8GWXwQsvxB2NiCSp2BOBmfUjJIJKH2V197HunufueTk5OQ0XXCrbuBFOOw0mT4b/+R8444y4IxKRJBXrk8VmdijwGPALd18bZyxppagozCM8fXqYR/jCC+OOSESSWGyJwMw6A88Cv3L3RXHFkZaWLAnPCkyYAOecE3c0IpLkIksEZjYR6Au0NbMCYBTQCMDdxwA3AW2Ah8wMYKu750UVT0bYti2MFtqzJ+Tnq1FYRKolskTg7oN3sf3XwK+j+v6Ms3kznHpqGDzu6quVBESk2mJvLJZ6sGULnHUWTJ0KrVvHHY2IpBglglRXUgLnnx+eGn7wQRg2LO6IRCTFKBGkumuugaeeCpPJXHJJ3NGISApSIkh13bqFuQSuuy7uSEQkRWmGslS1fj20bKlnBESkzlQiSEXvvQdduoTB40RE6kiJINV8+WUYOqJdOzjkkLijEZE0oESQSkqHjtiyJfQSatUq7ohEJA2ojSBVlJTAr34FCxfCq69C9+5xRyQiaUIlglRRUgL77gv33KPpJUWkXqlEkArcITs7PDDmHnc0IpJmVCJIdsuXQ69eMH9+eB8G6BMRqTdKBMlsyxY4+2z4/HPYffe4oxGRNKWqoWR27bXw/vthlrFu3eKORkTSlEoEyWrKFLjvPrj8cjjzzLijEZE0pkSQrMaPh0MPDfMNi4hESFVDyerpp6GwEJo0iTsSEUlzKhEkm9dfh1WrwpST++wTdzQikgEiSwRmNs7MVpvZwkq2H2hms8xss5n9Nqo4UsoXX4RxhEaMiDsSEckgUZYIxgMDqtj+LTACuDvCGFJHSQlccEF4cOxu/UlEpOFElgjcfQbhYl/Z9tXuPhsojiqGlPLoozBjRhhColOnuKMRkQyiNoJksHJlmHLy+ONDqUBEpAGlRCIws+FmNsfM5hQWFsYdTv1r3BhOOQXGjtUQEiLS4FIiEbj7WHfPc/e8nJycuMOpfzk5MGEC7Ldf3JGISAZKiUSQtoqKwlhCn3wSdyQiksGi7D46EZgFdDezAjMbZmYXmdlFie37mFkBcBVwQ2KfPaOKJynddlsYR2j9+rgjEZEMVq0ni82sObDR3UvM7ADgQOBVd6+0x4+7D67qM939G6BjTYJNK4sWhR5CQ4fC0UfHHY2IZLDqlghmAE3NrAPwOvArwnMCUhvuMHIkNGsGd94ZdzQikuGqmwjM3b8HTgMecvczgYOjCyvNvfwyTJ0KN9+sYSREJHbVTgRmdjQwBHg5sS4rmpAyQN++cP/9cOmlcUciIlLt0UevAK4HnnP3j82sK/B2ZFGluxYtNJ6QiCSNapUI3P0ddz/Z3e8ys92ANe6uK1lNFRXBccfB9OlxRyIisl21EoGZPWVmeyZ6Dy0EPjGzq6MNLQ3dc08YT6hp07gjERHZrrptBD3cfQNwKvAqkEvoOSTV9c03Ybax00+Ho46KOxoRke2qmwgamVkjQiJ4MfH8gEcWVTq69VbYvBluvz3uSEREdlLdRPAIsAxoDswwsx8BG6IKKu2sXBmGmT7/fDjggLijERHZSbV6Dbn7A8ADZVZ9aWb9ogkpDe2zD4wbB336xB2JiMgPVHeIiZbAKOBniVXvALcAGiSnOrKyYMiQuKMQEalQdauGxgHfAWcllg3AE1EFlVZGjYJ77407ChGRSlU3Eezn7qPcPT+x3Ax0jTKwtLByZRhL6NNP445ERKRS1U0EG81sewW3mfUGNkYTUhq55x7Ytg2uvz7uSEREKlXdISYuAiYk2goA/gUMjSakNLFuXegpdPbZkJsbdzQiIpWqbq+h+cBPSieOcfcNZnYFsCDC2FLbmDFhSImr9QC2iCS3Gs1Q5u4bEk8YQ5hZTCrTuzf87nfQs2fckYiIVKm6VUMVsXqLIh0de2xYRESSXF3mLNYQExUpKQlzES9fHnckIiLVUmUiMLPvzGxDBct3wL67+N1xZrbazBZWst3M7AEzW2JmC8zsp3U4juTxxhtwww3wzjtxRyIiUi1VJgJ338Pd96xg2cPdd1WtNB4YUMX2XwDdEstw4OGaBJ60HnoIcnLgrLPijkREpFrqUjVUJXefAXxbxS6nABM8eB/Yy8zaRxVPg/jyS5gyBf7rv6BJk7ijERGplsgSQTV0AFaUeV+QWPcDZjbczOaY2ZzCwsIGCa5WxowJPy+8MN44RERqIM5EUG3uPtbd89w9LycnJ+5wKrdxI5x5JnTuHHckIiLVVpfuo3W1EuhU5n3HxLrUdd994OpMJSKpJc4SwYvAuYneQ0cB69396xjjqZsvvgg/TY9XiEhqiSwRmNlEYBbQ3cwKzGyYmV1kZhcldnkFyAeWAI8Cl0QVS+Q++QT23x8mTIg7EhGRGousasjdB+9iuwOXRvX9DeqJJyA7GwZU1VtWRCQ5pURjcVIrLoY//QkGDoR27eKORkSkxpQI6mrqVFi1KkxMLyKSgpQI6urPfw4lgZNOijsSEZFaibP7aHoYOxY++wwaNYo7EhGRWlGJoK5atoQjj4w7ChGRWlMiqIthw+Dpp+OOQkSkTpQIamvJEhg3DgoK4o5ERKROlAhqq7QkoOGmRSTFKRHU1qRJ0KcPdOq0631FRJKYEkFtLFwYlkGD4o5ERKTOlAhqY+NGOP54OOOMuCMREakzPUdQG0ccAdOmxR2FiEi9UImgptasCYuISJpQIqipP/4R9t0X1q2LOxIRkXqhRFBTzz8fniTea6+4IxERqRdKBDWxdCnMnw+nnhp3JCIi9UaJoCZeeCH8POWUeOMQEalHSgQ18fzzcMghYVpKEZE0EWkiMLMBZva5mS0xs+sq2P4jM5tmZgvMbLqZdYwynjp74gl45JG4oxARqVdRTl6fBTwI/ALoAQw2sx7ldrsbmODuhwK3AHdEFU+9yM2FY46JOwoRkXoVZYmgF7DE3fPdfQswCShfud4DeCvx+u0KtieP++6DZ5+NOwoRkXoXZSLoAKwo874gsa6s+cBpidf/AexhZm3Kf5CZDTezOWY2p7CwMJJgq1RcDKNGwauvNvx3i4hELO7G4t8Cx5nZPOA4YCWwrfxO7j7W3fPcPS8nJ6ehY4T334cNG2DAgIb/bhGRiEU51tBKoOwYzR0T67Zz969IlAjMrAVwuruvizCm2nn1VcjOhhNPjDsSEZF6F2WJYDbQzcxyzawxMAh4sewOZtbWzEpjuB4YF2E8tffqq6GRuGXLuCMREal3kSUCd98KXAa8BnwKTHb3j83sFjM7ObFbX+BzM1sE7A3cFlU8tbZxY2gjULWQiKQpc/e4Y6iRvLw8nzNnTsN/cUkJ7BZ3k4qISO2Y2Vx3z6tom65su1KaKJUERCRN6epWlW3boGvXMPS0iEiaUiKoyvz5sGwZtG4ddyQiIpFRIqjKW4mHnvv1izcOEZEIKRFU5a234KCDoH37uCMREYmMEkFliothxgw4/vi4IxERiVSUTxanto0b4fLLoX//uCMREYmUEkFl9twT7kjuUbFFROqDqoYqM28ebNoUdxQiIpFTIqjIxo1w9NFwww1xRyIiEjklgorMmgWbN0PfvnFHIiISOSWCirz3HpjBscfGHYmISOSUCCoycyYccoiGnRaRjKBEUF5JSZiRTJPUi0iGUPfRirz6aug+KiKSAZQIytttt9BjSEQkQ6hqqLynn4apU+OOQkSkwSgRlHfTTfDww3FHISLSYJQIylqzBhYtUkOxiGSUSBOBmQ0ws8/NbImZXVfB9s5m9raZzTOzBWZ2UpTx7NKsWeGn2ghEJINElgjMLAt4EPgF0AMYbGY9yu12AzDZ3Q8DBgEPRRVPtcyaBdnZkFfh/M4iImkpyhJBL2CJu+e7+xZgEnBKuX0cKO2n2RL4KsJ4du2jj+Cww2D33WMNQ0SkIUXZfbQDsKLM+wLgyHL7jAZeN7PLgebAiRV9kJkNB4YDdO7cud4D3e7FF+Hbb6P7fBGRJBR3Y/FgYLy7dwROAv5kZj+Iyd3Hunueu+fl5OREF40ZtGkT3eeLiCShKBPBSqBTmfcdE+vKGgZMBnD3WUBToG2EMVXuqafgggs0B4GIZJwoE8FsoJuZ5ZpZY0Jj8Ivl9lkOnABgZgcREkFhhDFV7qWX4I03oGnTWL5eRCQukSUCd98KXAa8BnxK6B30sZndYmYnJ3b7DfBfZjYfmAic5+4eVUxVmjlTzw+ISEaKdKwhd38FeKXcupvKvP4E6B1lDNVSUADLl8NVV8UdiYhIg4u7sTg56EEyEclgSgQAW7fCj38MPXvGHYmISINTIgAYPBgWLIDGjeOORESkwSkRlJRATO3TIiLJQIlg5kxo1y5MTykikoGUCGbNCsNPd+0adyQiIrFQIpg5E/bfP5QKREQyUGYnAnc9SCYiGS+zE0F+PqxerUQgIhktsxNBo0bwm99Av35xRyIiEptIh5hIep07w913xx2FiEisMrtE8M9/wpYtcUchIhKrzE0Ea9fC4YerRCAiGS9zE8HMmeFnnz7xxiEiErPMTQTvvhsai484Iu5IRERilbmJ4L33QhJo1izuSEREYpWZiaCoCObMUbWQiAiZ2n20aVOYNg322SfuSEREYhdpicDMBpjZ52a2xMyuq2D7vWb2YWJZZGbrooxnu+xsOPZY6NatQb5ORCSZRZYIzCwLeBD4BdADGGxmPcru4+5XuntPd+8J/AF4Nqp4ynwp3HwzzJsX+VeJiKSCKEsEvYAl7p7v7luAScApVew/GJgYYTzBrFkwenSYkUxERCJtI+gArCjzvgA4sqIdzexHQC7wViXbhwPDATp37ly7aFatgkcegWefhebN4bTTavc5IiJpJll6DQ0C/uru2yra6O5j3T3P3fNycnJq9w1bt8KoUTB/Plx1FeyxRx3CFRFJH1GWCFYCncq875hYV5FBwKURxgIdOsDjj8MXX8Dvfx/pV4mIpJIoE8FsoJuZ5RISwCDgP8vvZGYHAq2AWRHGElxwQeRfISKSaiKrGnL3rcBlwGvAp8Bkd//YzG4xs5PL7DoImOTuHlUsIiJSuUgfKHP3V4BXyq27qdz70VHGICIiVUuWxmIREYmJEoGISIZTIhARyXBKBCIiGU6JQEQkwykRiIhkOEu17vtmVgh8WctfbwusqcdwUoGOOTPomDNDXY75R+5e4Rg9KZcI6sLM5rh7XtxxNCQdc2bQMWeGqI5ZVUMiIhlOiUBEJMNlWiIYG3cAMdAxZwYdc2aI5Jgzqo1ARER+KNNKBCIiUo4SgYhIhsuYRGBmA8zsczNbYmbXxR1PfTGzTmb2tpl9YmYfm9nIxPrWZvaGmS1O/GyVWG9m9kDi77DAzH4a7xHUjpllmdk8M5uSeJ9rZv9IHNfTZtY4sb5J4v2SxPYusQZeB2a2l5n91cw+M7NPzezodD7PZnZl4t/0QjObaGZN0/E8m9k4M1ttZgvLrKvxeTWzoYn9F5vZ0JrEkBGJwMyygAeBXwA9gMFm1iPeqOrNVuA37t4DOAq4NHFs1wHT3L0bMC3xHsLfoFtiGQ483PAh14uRhAmPSt0F3Ovu+wP/AoYl1g8D/pVYf29iv1R1PzDV3Q8EfkI4/rQ8z2bWARgB5Ln7IUAWYRKrdDzP44EB5dbV6LyaWWtgFHAk0AsYVZo8qsXd034BjgZeK/P+euD6uOOK6FhfAP4P8DnQPrGuPfB54vUjwOAy+2/fL1UWwvzX04DjgSmAEZ62zC5/vgkz5B2deJ2d2M/iPoZaHHNLYGn52NP1PAMdgBVA68R5mwL8PF3PM9AFWFjb8woMBh4ps36n/Xa1ZESJgB3/qEoVJNallURx+DDgH8De7v51YtM3wN6J1+nwt7gPuAYoSbxvA6zzMD0q7HxM2483sX19Yv9UkwsUAk8kqsQeM7PmpOl5dveVwN3AcuBrwnmbS/qf51I1Pa91Ot+ZkgjSnpm1AP4GXOHuG8pu83CLkBb9hM3sl8Bqd58bdywNLBv4KfCwux8G/Jsd1QVA2p3nVsAphAS4L9CcH1afZISGOK+ZkghWAp3KvO+YWJcWzKwRIQn8xd2fTaxeZWbtE9vbA6sT61P9b9EbONnMlgGTCNVD9wN7mVnpHNxlj2n78Sa2twTWNmTA9aQAKHD3fyTe/5WQGNL1PJ8ILHX3QncvBp4lnPt0P8+lanpe63S+MyURzAa6JXocNCY0Or0Yc0z1wswMeBz41N3/t8ymF4HSngNDCW0HpevPTfQ+OApYX6YImvTc/Xp37+juXQjn8S13HwK8DZyR2K388Zb+Hc5I7J9yd83u/g2wwsy6J1adAHxCmp5nQpXQUWa2e+LfeOnxpvV5LqOm5/U1oL+ZtUqUpvon1lVP3I0kDdgYcxKwCPgC+H3c8dTjcfUhFBsXAB8mlpMI9aPTgMXAm0DrxP5G6EH1BfARoVdG7MdRy2PvC0xJvO4KfAAsAZ4BmiTWN028X5LY3jXuuOtwvD2BOYlz/TzQKp3PM3Az8BmwEPgT0CQdzzMwkdAOUkwo+Q2rzXkFLkgc/xLg/JrEoCEmREQyXKZUDYmISCWUCEREMpwSgYhIhlMiEBHJcEoEIiIZTolApBwz22ZmH5ZZ6m20WjPrUnaUSZFkkL3rXUQyzkZ37xl3ECINRSUCkWoys2Vm9t9m9pGZfWBm+yfWdzGztxLjw08zs86J9Xub2XNmNj+xHJP4qCwzezQx1v7rZtYstoMSQYlApCLNylUNnV1m23p3/zHwR8IoqAB/AJ5090OBvwAPJNY/ALzj7j8hjAv0cWJ9N+BBdz8YWAecHunRiOyCniwWKcfMity9RQXrlwHHu3t+YqC/b9y9jZmtIYwdX5xY/7W7tzWzQqCju28u8xldgDc8TDiCmV0LNHL3Wxvg0EQqpBKBSM14Ja9rYnOZ19tQW53ETIlApGbOLvNzVuL1TMJIqABDgHcTr6cBF8P2OZZbNlSQIjWhOxGRH2pmZh+WeT/V3Uu7kLYyswWEu/rBiXWXE2YOu5owi9j5ifUjgbFmNoxw538xYZRJkaSiNgKRakq0EeS5+5q4YxGpT6oaEhHJcCoRiIhkOJUIREQynBKBiEiGUyIQEclwSgQiIhlOiUBEJMP9f1X+T6YsP/oXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iter_count, y_loss, 'r--')\n",
    "#plt.plot(iter_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement weighted K-Neighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that training a KNN classifier is simply memorizing a training sample. \n",
    "\n",
    "The process of applying a classifier for one object is to find the distances from it to all objects in the training data, then select the k nearest objects (neighbors) and return the most common class among these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give the nearest neighbors weights in accordance with the distance of the object to them. In the simplest case (as in your assignment), you can set the weights inversely proportional to that distance. \n",
    "\n",
    "$$w_{i} = \\frac{1}{d_{i} + eps},$$\n",
    "\n",
    "where $d_{i}$ is the distance between object and i-th nearest neighbor and $eps$ is the small value to prevent division by zero.\n",
    "\n",
    "In case of 'uniform' weights, all k nearest neighbors are equivalent (have equal weight, for example $w_{i} = 1, \\forall i \\in(1,k)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the probability of classes, it is necessary to normalize the weights of each class, dividing them by the sum:\n",
    "\n",
    "$$p_{i} = \\frac{w_{i}}{\\sum_{j=1}^{c}w_{j}},$$\n",
    "\n",
    "where $p_i$ is probability of i-th class and $c$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits. By implementing this algorithm, you will be able to classify numbers not only into \"even\" or \"odd\", but into their real representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNeighborsClassifier:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, weights='uniform', eps=1e-9):\n",
    "        \"\"\"K-Nearest Neighbors classifier.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: int, default=5\n",
    "                Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "            weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "                Weight function used in prediction.  Possible values:\n",
    "                - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "                  are weighted equally.\n",
    "                - 'distance' : weight points by the inverse of their distance.\n",
    "                  in this case, closer neighbors of a query point will have a\n",
    "                  greater influence than neighbors which are further away.\n",
    "            eps : float, default=1e-5\n",
    "                Epsilon to prevent division by 0 \n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def get_pairwise_distances(self, X, Y):\n",
    "        \"\"\"\n",
    "        Returnes matrix of the pairwise distances between the rows from both X and Y.\n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            Y: numpy array of shape (k_samples, n_features)\n",
    "        Returns:\n",
    "            P: numpy array of shape (n_samples, k_samples)\n",
    "                Matrix in which (i, j) value is the distance \n",
    "                between i'th row from the X and j'th row from the Y.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def get_class_weights(self, y, weights):\n",
    "        \"\"\"\n",
    "        Returns a vector with sum of weights for each class \n",
    "        Args:\n",
    "            y: numpy array of shape (n_samles,)\n",
    "            weights: numpy array of shape (n_samples,)\n",
    "                The weights of the corresponding points of y.\n",
    "        Returns:\n",
    "            p: numpy array of shape (n_classes)\n",
    "                Array where the value at the i-th position \n",
    "                corresponds to the weight of the i-th class.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.points = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples, n_classes)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'points'):\n",
    "            P = self.get_pairwise_distances(X, self.points)\n",
    "            \n",
    "            weights_of_points = np.ones(P.shape)\n",
    "            if self.weights == 'distance':\n",
    "                weights_of_points = 'your code'\n",
    "                \n",
    "            # <your code>\n",
    "            pass\n",
    "        \n",
    "        else: \n",
    "            raise NotFittedError(\"CustomKNeighborsClassifier instance is not fitted yet\")\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomKNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.get_pairwise_distances(np.array([[0  , 1]  , [1, 1]]), \n",
    "                                                np.array([[0.5, 0.5], [1, 0]])),\n",
    "                   np.array([[0.70710678, 1.41421356],\n",
    "                             [0.70710678, 1.        ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_ = ['one', 'two', 'three']\n",
    "assert np.allclose(model.get_class_weights(np.array(['one', 'one', 'three', 'two']), np.array([1, 1, 0, 4])), \n",
    "                   np.array([2,4,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "knn.fit(X_train, list(map(str, y_train)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.predict_proba(X_test), knn.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc == 1\n",
    "assert test_acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Take a look at the confusion matrix and tell what numbers the model confuses and why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different n_neighbors parameters and compare the output probabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare both 'uniform' and 'distance' weights and share your thoughts in what situations which parameter can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest another distance measurement function that could improve the quality of the classification for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest different task and distance function that you think would be suitable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Synthetic Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/tabular-playground-series-apr-2021/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n",
    "\n",
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model, load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "\n",
    "**Note**. X points will depend on your kaggle public leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.79 \\leq score < 0.80,$$\n",
    "$$ f(score) = 2.5, \\ \\ 0.80 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 4.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
